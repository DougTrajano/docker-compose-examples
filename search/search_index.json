{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Overview \u2693\ufe0e This project contains a set of examples of using Docker Compose to deploy a variety of applications. Examples \u2693\ufe0e DS Stack - JupyterLab + MLflow MinIO STS - MinIO S3 Gateway + Keycloak + MinIO Console + Etcd JaCaMo - Framework for Multi-Agent Programming Data Privacy \u2693\ufe0e We are committed to protecting your privacy. We do not collect any data on these examples as the purpose of this project is to demonstrate the use of Docker Compose. Docker volumes \u2693\ufe0e These examples use Docker volumes to share data between containers. All Docker volumes are saved to the /data_* directory in each stack. The .gitignore file in the root of this project contains a pattern that will ignore all directories that inlcude data_* . License \u2693\ufe0e The project is licensed under the Apache 2.0 License . The applications used in the examples can have their own license.","title":"Overview"},{"location":"index.html#overview","text":"This project contains a set of examples of using Docker Compose to deploy a variety of applications.","title":"Overview"},{"location":"index.html#examples","text":"DS Stack - JupyterLab + MLflow MinIO STS - MinIO S3 Gateway + Keycloak + MinIO Console + Etcd JaCaMo - Framework for Multi-Agent Programming","title":"Examples"},{"location":"index.html#data-privacy","text":"We are committed to protecting your privacy. We do not collect any data on these examples as the purpose of this project is to demonstrate the use of Docker Compose.","title":"Data Privacy"},{"location":"index.html#docker-volumes","text":"These examples use Docker volumes to share data between containers. All Docker volumes are saved to the /data_* directory in each stack. The .gitignore file in the root of this project contains a pattern that will ignore all directories that inlcude data_* .","title":"Docker volumes"},{"location":"index.html#license","text":"The project is licensed under the Apache 2.0 License . The applications used in the examples can have their own license.","title":"License"},{"location":"examples/ds-stack.html","text":"Data Science stack \u2693\ufe0e This Docker Compose stack is a collection of services that can be used to run a Data Science environment. JupyterLab MLFlow Server Prerequisites \u2693\ufe0e Docker Docker Compose On desktop systems like Docker Desktop for Mac and Windows, Docker Compose is included as part of those desktop installs. Services \u2693\ufe0e MLFlow \u2693\ufe0e MLflow is an open source platform to manage the ML lifecycle, including experimentation, reproducibility, deployment, and a central model registry. MLflow currently offers four components: MLflow Tracking MLflow Projects MLflow Models Mlflow Registry JupyterLab \u2693\ufe0e JupyterLab is a web-based interactive development environment for Jupyter notebooks, code, and data. JupyterLab is flexible: configure and arrange the user interface to support a wide range of workflows in data science, scientific computing, and machine learning. JupyterLab is extensible and modular: write plugins that add new components and integrate with existing ones. Dataiku Data Science Studio (DSS) \u2693\ufe0e Dataiku enables you to create, share, and reuse applications that leverage data and machine learning to extend and automate decision making. Project setup \u2693\ufe0e Environment variables \u2693\ufe0e You need to set the following environment variables to use this Docker Compose . The best way to do this is to add them to a .env file in the same directory as docker-compose.yml . .env 1 2 3 4 5 6 7 8 9 10 11 12 MLFLOW_PORT = 5000 MLFLOW_DB_USERNAME = mlflow MLFLOW_DB_PASSWORD = mlflow MLFLOW_DB_DATABASE = mlflow MLFLOW_DB_PORT = 5432 MINIO_ACCESS_KEY = minio MINIO_SECRET_KEY = minio123 JUPYTERLAB_PORT = 8888 JUPYTERLAB_TOKEN = '' JUPYTERLAB_PASSWORD = '' Docker Compose up \u2693\ufe0e To run all the required services, execute the following command: 1 docker-compose up Dataiku Data Science Studio (DSS) is an optional service. To run the stack with it, execute the following command: 1 docker-compose --profile dataiku up You can now access the following endpoints: Endpoint Description http://localhost:8888/ JupyterLab http://localhost:5000/ MLflow UI http://localhost:11000/ Dataiku (optional) Next features \u2693\ufe0e Add optional profiles with more tools such as: Airflow - Develop, schedule, and monitor workflows Redash - Visualization tool Postgres - Relational Database Feast - Feature Store So you can up your stack with optional tools using the same docker-compose.yml file. 1 docker-compose --profile airflow --profile feast up The result of this command will launch JupyterLab, MLFlow Server (with its postgres and minio), Kubeflow and Redash. Change Log \u2693\ufe0e All notable changes to this project will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning . 1.1.0 (2021-08-15) \u2693\ufe0e Added Dataiku service as a profile --profile dataiku . 1.0.0 (2021-08-07) \u2693\ufe0e Initial release with the following features: MLflow Tracking Server. JupyterLab. GitHub Page with the documentation. GitHub Actions (CI) to verify the docker-compose.yml file and deploy the documentation.","title":"DS Stack"},{"location":"examples/ds-stack.html#data-science-stack","text":"This Docker Compose stack is a collection of services that can be used to run a Data Science environment. JupyterLab MLFlow Server","title":"Data Science stack"},{"location":"examples/ds-stack.html#prerequisites","text":"Docker Docker Compose On desktop systems like Docker Desktop for Mac and Windows, Docker Compose is included as part of those desktop installs.","title":"Prerequisites"},{"location":"examples/ds-stack.html#services","text":"","title":"Services"},{"location":"examples/ds-stack.html#mlflow","text":"MLflow is an open source platform to manage the ML lifecycle, including experimentation, reproducibility, deployment, and a central model registry. MLflow currently offers four components: MLflow Tracking MLflow Projects MLflow Models Mlflow Registry","title":"MLFlow"},{"location":"examples/ds-stack.html#jupyterlab","text":"JupyterLab is a web-based interactive development environment for Jupyter notebooks, code, and data. JupyterLab is flexible: configure and arrange the user interface to support a wide range of workflows in data science, scientific computing, and machine learning. JupyterLab is extensible and modular: write plugins that add new components and integrate with existing ones.","title":"JupyterLab"},{"location":"examples/ds-stack.html#dataiku-data-science-studio-dss","text":"Dataiku enables you to create, share, and reuse applications that leverage data and machine learning to extend and automate decision making.","title":"Dataiku Data Science Studio (DSS)"},{"location":"examples/ds-stack.html#project-setup","text":"","title":"Project setup"},{"location":"examples/ds-stack.html#environment-variables","text":"You need to set the following environment variables to use this Docker Compose . The best way to do this is to add them to a .env file in the same directory as docker-compose.yml . .env 1 2 3 4 5 6 7 8 9 10 11 12 MLFLOW_PORT = 5000 MLFLOW_DB_USERNAME = mlflow MLFLOW_DB_PASSWORD = mlflow MLFLOW_DB_DATABASE = mlflow MLFLOW_DB_PORT = 5432 MINIO_ACCESS_KEY = minio MINIO_SECRET_KEY = minio123 JUPYTERLAB_PORT = 8888 JUPYTERLAB_TOKEN = '' JUPYTERLAB_PASSWORD = ''","title":"Environment variables"},{"location":"examples/ds-stack.html#docker-compose-up","text":"To run all the required services, execute the following command: 1 docker-compose up Dataiku Data Science Studio (DSS) is an optional service. To run the stack with it, execute the following command: 1 docker-compose --profile dataiku up You can now access the following endpoints: Endpoint Description http://localhost:8888/ JupyterLab http://localhost:5000/ MLflow UI http://localhost:11000/ Dataiku (optional)","title":"Docker Compose up"},{"location":"examples/ds-stack.html#next-features","text":"Add optional profiles with more tools such as: Airflow - Develop, schedule, and monitor workflows Redash - Visualization tool Postgres - Relational Database Feast - Feature Store So you can up your stack with optional tools using the same docker-compose.yml file. 1 docker-compose --profile airflow --profile feast up The result of this command will launch JupyterLab, MLFlow Server (with its postgres and minio), Kubeflow and Redash.","title":"Next features"},{"location":"examples/ds-stack.html#change-log","text":"All notable changes to this project will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning .","title":"Change Log"},{"location":"examples/ds-stack.html#110-2021-08-15","text":"Added Dataiku service as a profile --profile dataiku .","title":"1.1.0 (2021-08-15)"},{"location":"examples/ds-stack.html#100-2021-08-07","text":"Initial release with the following features: MLflow Tracking Server. JupyterLab. GitHub Page with the documentation. GitHub Actions (CI) to verify the docker-compose.yml file and deploy the documentation.","title":"1.0.0 (2021-08-07)"},{"location":"examples/jacamo.html","text":"JaCaMo Web \u2693\ufe0e This project contains a Docker Compose that deploys a JaCaMo-Web . Prerequisites \u2693\ufe0e Docker Docker Compose On desktop systems like Docker Desktop for Mac and Windows, Docker Compose is included as part of those desktop installs. Services \u2693\ufe0e JaCaMo Web \u2693\ufe0e Jacamo-web is an interactive programming IDE based on JaCaMo , a Multi-Agent System (MAS) Oriented Programming platform. The interactive development allows making changes on instances of agents, artefacts and organisations, which means that the system can be updated while it is running. More details in github.com/jacamo-lang/jacamo-web .","title":"JaCaMo"},{"location":"examples/jacamo.html#jacamo-web","text":"This project contains a Docker Compose that deploys a JaCaMo-Web .","title":"JaCaMo Web"},{"location":"examples/jacamo.html#prerequisites","text":"Docker Docker Compose On desktop systems like Docker Desktop for Mac and Windows, Docker Compose is included as part of those desktop installs.","title":"Prerequisites"},{"location":"examples/jacamo.html#services","text":"","title":"Services"},{"location":"examples/jacamo.html#jacamo-web_1","text":"Jacamo-web is an interactive programming IDE based on JaCaMo , a Multi-Agent System (MAS) Oriented Programming platform. The interactive development allows making changes on instances of agents, artefacts and organisations, which means that the system can be updated while it is running. More details in github.com/jacamo-lang/jacamo-web .","title":"JaCaMo Web"},{"location":"examples/minio-sts.html","text":"Minio STS \u2693\ufe0e In this example, we will set up a MinIO Gateway S3 with STS (Security Token Service) using Docker Compose . Prerequisites \u2693\ufe0e Docker Docker Compose On desktop systems like Docker Desktop for Mac and Windows, Docker Compose is included as part of those desktop installs. Services \u2693\ufe0e MinIO Server - S3 Gateway \u2693\ufe0e MinIO is a High Performance Object Storage released under Apache License v2.0. It is API compatible with Amazon S3 cloud storage service. Use MinIO to build high performance infrastructure for machine learning, analytics and application data workloads. Etcd \u2693\ufe0e etcd is a distributed key-value store designed to securely store data across a cluster. etcd is widely used in production on account of its reliability, fault-tolerance and ease of use. Keycloak \u2693\ufe0e Keycloak is an Open Source Identity and Access Management solution for modern Applications and Services. Postgres - Keycloak Database \u2693\ufe0e PostgreSQL is a powerful, open source object-relational database. MinIO Console - Optional \u2693\ufe0e A graphical user interface for MinIO . Project setup \u2693\ufe0e Environment variables \u2693\ufe0e You need to set the following environment variables to use this Docker Compose . .env 1 2 3 4 MINIO_ACCESS_KEY = minio MINIO_SECRET_KEY = minio123 MINIO_ROOT_USER = YOUR-AWS-ACCESS-KEY MINIO_ROOT_PASSWORD = YOUR-AWS-SECRET-KEY Docker Compose up \u2693\ufe0e To run all the required services, execute the following command: 1 docker-compose up MinIO Console is an optional service. To run the stack with it, execute the following command: 1 docker-compose --profile console up Keycloak configuration \u2693\ufe0e You need to make some changes to the Keycloak Realm in order to use MinIO. Navigate to the Keycloak UI: http://localhost:8080/auth/ . In the left menu, click on Clients . Click on Edit for account client. Turn on Implicit Flow Enabled . Add \"*\" to the Valid Redirect URIs field. Click on Save . Also in the account client, click on Mappers . Click on Create . Fill in the Name field with \"policy\". Change the Mapper Type to \"User Attribute\". Fill in the User Attribute field with \"policy\". Fill in the Token Claim Name field with \"policy\". Click on Save . In the left menu, click on Users . Click on View all users . Click on Edit for user \"admin\". Go to Attributes tab. Fill in the Key field with \"policy\" and Value field with \"readwrite\". Click on Add and then Save . Right now, you should be able to log in to MinIO using the policies that you created in Keycloak. There's a lot more configuration that you can do. Please refer to the related links for more information. Known issues \u2693\ufe0e As Keycloak takes a long time to start up, you may need to restart the MinIO container after Keycloak is ready. Related Links \u2693\ufe0e MinIO | Learn how to deploy MinIO with Amazon S3 MinIO | Learn how to configure MinIO for Security Token Service","title":"MinIO STS"},{"location":"examples/minio-sts.html#minio-sts","text":"In this example, we will set up a MinIO Gateway S3 with STS (Security Token Service) using Docker Compose .","title":"Minio STS"},{"location":"examples/minio-sts.html#prerequisites","text":"Docker Docker Compose On desktop systems like Docker Desktop for Mac and Windows, Docker Compose is included as part of those desktop installs.","title":"Prerequisites"},{"location":"examples/minio-sts.html#services","text":"","title":"Services"},{"location":"examples/minio-sts.html#minio-server---s3-gateway","text":"MinIO is a High Performance Object Storage released under Apache License v2.0. It is API compatible with Amazon S3 cloud storage service. Use MinIO to build high performance infrastructure for machine learning, analytics and application data workloads.","title":"MinIO Server - S3 Gateway"},{"location":"examples/minio-sts.html#etcd","text":"etcd is a distributed key-value store designed to securely store data across a cluster. etcd is widely used in production on account of its reliability, fault-tolerance and ease of use.","title":"Etcd"},{"location":"examples/minio-sts.html#keycloak","text":"Keycloak is an Open Source Identity and Access Management solution for modern Applications and Services.","title":"Keycloak"},{"location":"examples/minio-sts.html#postgres---keycloak-database","text":"PostgreSQL is a powerful, open source object-relational database.","title":"Postgres - Keycloak Database"},{"location":"examples/minio-sts.html#minio-console---optional","text":"A graphical user interface for MinIO .","title":"MinIO Console - Optional"},{"location":"examples/minio-sts.html#project-setup","text":"","title":"Project setup"},{"location":"examples/minio-sts.html#environment-variables","text":"You need to set the following environment variables to use this Docker Compose . .env 1 2 3 4 MINIO_ACCESS_KEY = minio MINIO_SECRET_KEY = minio123 MINIO_ROOT_USER = YOUR-AWS-ACCESS-KEY MINIO_ROOT_PASSWORD = YOUR-AWS-SECRET-KEY","title":"Environment variables"},{"location":"examples/minio-sts.html#docker-compose-up","text":"To run all the required services, execute the following command: 1 docker-compose up MinIO Console is an optional service. To run the stack with it, execute the following command: 1 docker-compose --profile console up","title":"Docker Compose up"},{"location":"examples/minio-sts.html#keycloak-configuration","text":"You need to make some changes to the Keycloak Realm in order to use MinIO. Navigate to the Keycloak UI: http://localhost:8080/auth/ . In the left menu, click on Clients . Click on Edit for account client. Turn on Implicit Flow Enabled . Add \"*\" to the Valid Redirect URIs field. Click on Save . Also in the account client, click on Mappers . Click on Create . Fill in the Name field with \"policy\". Change the Mapper Type to \"User Attribute\". Fill in the User Attribute field with \"policy\". Fill in the Token Claim Name field with \"policy\". Click on Save . In the left menu, click on Users . Click on View all users . Click on Edit for user \"admin\". Go to Attributes tab. Fill in the Key field with \"policy\" and Value field with \"readwrite\". Click on Add and then Save . Right now, you should be able to log in to MinIO using the policies that you created in Keycloak. There's a lot more configuration that you can do. Please refer to the related links for more information.","title":"Keycloak configuration"},{"location":"examples/minio-sts.html#known-issues","text":"As Keycloak takes a long time to start up, you may need to restart the MinIO container after Keycloak is ready.","title":"Known issues"},{"location":"examples/minio-sts.html#related-links","text":"MinIO | Learn how to deploy MinIO with Amazon S3 MinIO | Learn how to configure MinIO for Security Token Service","title":"Related Links"}]}